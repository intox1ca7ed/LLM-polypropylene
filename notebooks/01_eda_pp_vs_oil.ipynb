{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ba6546",
   "metadata": {},
   "source": [
    "# Polypropylene vs Upstream Drivers: Exploratory Data Analysis\n",
    "\n",
    "Explore whether PP prices co-move with propylene (PGP) and crude; establish sensible baselines before expanding into richer feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb65e87",
   "metadata": {},
   "source": [
    "Local files under `data/` are used throughout. Units, currencies, and frequencies may differ, so we normalize and resample to monthly for comparability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6e58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q pandas numpy matplotlib seaborn statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6c8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "PROJECT_DIR = Path.cwd().parent\n",
    "DATA_DIR = PROJECT_DIR / \"data\"\n",
    "PLOTS_DIR = PROJECT_DIR / \"plots\"\n",
    "ARTIFACTS_DIR = PROJECT_DIR / \"artifacts\"\n",
    "for folder in (PLOTS_DIR, ARTIFACTS_DIR):\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_DIR / \"src\"))\n",
    "from eda_utils import (\n",
    "    build_audit_table,\n",
    "    compute_log_returns,\n",
    "    cross_corr_scan,\n",
    "    find_candidate_files,\n",
    "    load_series,\n",
    "    normalize_base_100,\n",
    "    plot_beta_scaled_spread,\n",
    "    plot_leadlag_heatmap,\n",
    "    plot_normalized_levels,\n",
    "    plot_rolling_beta,\n",
    "    plot_scatter_returns,\n",
    "    rolling_beta_ols,\n",
    "    rolling_corr,\n",
    "    to_monthly,\n",
    ")\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 150\n",
    "CLASS_KEYWORDS = {\n",
    "    \"PP\": [\"pp\", \"polypropylene\"],\n",
    "    \"PGP\": [\"pgp\", \"propylene\", \"c3\"],\n",
    "    \"CRUDE\": [\"brent\", \"wti\", \"crude\", \"oil\"],\n",
    "    \"NAPHTHA\": [\"naphtha\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e64650",
   "metadata": {},
   "source": [
    "## Discovery & loading\n",
    "\n",
    "Find candidate files by keyword, load each series with `eda_utils.load_series`, and capture metadata for traceability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d7588",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_map = {\n",
    "    label: find_candidate_files(DATA_DIR, patterns)\n",
    "    for label, patterns in CLASS_KEYWORDS.items()\n",
    "}\n",
    "\n",
    "loaded_series = {}\n",
    "discovery_records = []\n",
    "for label, paths in candidate_map.items():\n",
    "    if not paths:\n",
    "        print(\n",
    "            f\"No {label} series found. Expected keywords: {CLASS_KEYWORDS[label]}\"\n",
    "        )\n",
    "        continue\n",
    "    series_list = []\n",
    "    for path in paths:\n",
    "        try:\n",
    "            df = load_series(path, f\"{label}|{path.stem}\")\n",
    "        except Exception as exc:\n",
    "            print(f\"Skipping {path.name}: {exc}\")\n",
    "            continue\n",
    "        series_list.append(df)\n",
    "        discovery_records.append(\n",
    "            {\n",
    "                \"class\": label,\n",
    "                \"series_name\": df.attrs.get(\"series_name\"),\n",
    "                \"file\": path.relative_to(PROJECT_DIR),\n",
    "                \"date_column\": df.attrs.get(\"date_column\"),\n",
    "                \"value_column\": df.attrs.get(\"value_column\"),\n",
    "                \"rows_raw\": df.attrs.get(\"rows_raw\"),\n",
    "                \"rows_clean\": df.attrs.get(\"rows_clean\"),\n",
    "                \"start\": df.attrs.get(\"start\"),\n",
    "                \"end\": df.attrs.get(\"end\"),\n",
    "            }\n",
    "        )\n",
    "    if series_list:\n",
    "        loaded_series[label] = series_list\n",
    "discovery_df = pd.DataFrame(discovery_records)\n",
    "if not discovery_df.empty:\n",
    "    display(discovery_df)\n",
    "else:\n",
    "    display(Markdown(\"**No qualifying series loaded — add data to proceed.**\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3750572e",
   "metadata": {},
   "source": [
    "_Table note:_ The discovery summary above lists every file that matched our keyword scan and highlights which date/value columns were inferred so you can quickly spot mislabelled sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88757fca",
   "metadata": {},
   "source": [
    "## Monthly alignment\n",
    "\n",
    "Resample each raw series to monthly means, keep one preferred series per class, and form wide outer/inner tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e18ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_tables = {}\n",
    "preferred = {}\n",
    "for label, series_list in loaded_series.items():\n",
    "    monthly_list = [to_monthly(series) for series in series_list]\n",
    "    table = pd.concat(monthly_list, axis=1)\n",
    "    table = table.loc[~table.index.duplicated()].sort_index()\n",
    "    monthly_tables[label] = table\n",
    "    preferred_series_name = table.count().sort_values(ascending=False).index[0]\n",
    "    preferred[label] = table[preferred_series_name]\n",
    "wide_outer = pd.concat(monthly_tables.values(), axis=1) if monthly_tables else pd.DataFrame()\n",
    "monthly_inner = pd.concat(preferred, axis=1).dropna() if preferred else pd.DataFrame()\n",
    "display(Markdown(f\"**Monthly outer shape:** {wide_outer.shape}\"))\n",
    "display(Markdown(f\"**Monthly inner shape:** {monthly_inner.shape}\"))\n",
    "wide_outer.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc4d539",
   "metadata": {},
   "outputs": [],
   "source": [
    "audit_input = {label: series for label, series in preferred.items()}\n",
    "audit_table = build_audit_table(audit_input) if audit_input else pd.DataFrame()\n",
    "if not audit_table.empty:\n",
    "    display(audit_table)\n",
    "    audit_table.to_csv(ARTIFACTS_DIR / \"data_audit.csv\", index=False)\n",
    "monthly_inner.to_csv(ARTIFACTS_DIR / \"merged_monthly_prices.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4748e4",
   "metadata": {},
   "source": [
    "_Audit note:_ Use the audit table to confirm coverage (first/last date, missing %), plus currency/unit hints pulled from the raw files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5dc394",
   "metadata": {},
   "source": [
    "## Levels (normalized)\n",
    "\n",
    "Normalize each preferred level series to 100 at the first common observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c6a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not monthly_inner.empty:\n",
    "    norm_levels = normalize_base_100(monthly_inner)\n",
    "    fig = plot_normalized_levels(norm_levels, \"Normalized Levels (base = 100)\")\n",
    "    display(fig)\n",
    "    fig.savefig(PLOTS_DIR / \"levels_normalized.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "else:\n",
    "    display(Markdown(\"*No overlapping monthly series available.*\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c834e91b",
   "metadata": {},
   "source": [
    "_Figure:_ Normalized level lines let us compare PP and crude trends on a common 100-base scale so different currencies/units do not mask co-movement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17f1ca3",
   "metadata": {},
   "source": [
    "## Returns & correlations\n",
    "\n",
    "Compute log returns, save clean datasets, and prepare diagnostics for PP vs key drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b417f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not monthly_inner.empty:\n",
    "    log_returns = compute_log_returns(monthly_inner).dropna()\n",
    "    log_returns.to_csv(ARTIFACTS_DIR / \"merged_monthly_returns.csv\")\n",
    "    display(log_returns.describe().T)\n",
    "else:\n",
    "    log_returns = pd.DataFrame()\n",
    "    display(Markdown(\"*Returns unavailable; add overlapping series.*\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762bc30d",
   "metadata": {},
   "source": [
    "_Table detail:_ The return summary offers mean/volatility/skewness for each monthly log-return series so you can judge distribution shape before modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52917c3",
   "metadata": {},
   "source": [
    "## Headline visuals\n",
    "\n",
    "Key diagnostics for PP versus crude oil (or other drivers when available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f633eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "if {\"PP\", \"CRUDE\"} <= set(monthly_inner.columns):\n",
    "    pp = monthly_inner[\"PP\"]\n",
    "    crude = monthly_inner[\"CRUDE\"]\n",
    "    pp_ret = log_returns[\"PP\"]\n",
    "    crude_ret = log_returns[\"CRUDE\"]\n",
    "\n",
    "    rolling_beta = rolling_beta_ols(pp_ret, crude_ret, window=12)\n",
    "    if not rolling_beta.empty:\n",
    "        fig = plot_rolling_beta(rolling_beta, \"Rolling 12M OLS β: PP vs Crude\")\n",
    "        display(fig)\n",
    "        fig.savefig(PLOTS_DIR / \"rolling_beta_pp_crude.png\", bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    beta_series = rolling_beta[\"beta\"] if \"beta\" in rolling_beta else None\n",
    "    fig = plot_beta_scaled_spread(pp, crude, beta=None, rolling_beta=beta_series, title=\"Beta-scaled spread: PP vs Crude\")\n",
    "    display(fig)\n",
    "    fig.savefig(PLOTS_DIR / \"beta_scaled_spread_pp_crude.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig = plot_leadlag_heatmap(pp_ret, crude_ret, window=36, max_lag=12, title=\"Lead/Lag heatmap: PP vs Crude\")\n",
    "    display(fig)\n",
    "    fig.savefig(PLOTS_DIR / \"leadlag_heatmap_pp_crude.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    fig = plot_scatter_returns(pp_ret, crude_ret, title=\"Monthly log returns: PP vs Crude\", label_outliers=3)\n",
    "    display(fig)\n",
    "    fig.savefig(PLOTS_DIR / \"scatter_returns_pp_crude.png\", bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    rolling_corr_pp_crude = rolling_corr(pp_ret, crude_ret, window=12)\n",
    "    rolling_corr_pp_crude.to_csv(ARTIFACTS_DIR / \"rolling_corr_pp_crude.csv\")\n",
    "    corr_scan = cross_corr_scan(pp_ret, crude_ret, max_lag=12)\n",
    "    corr_scan.to_csv(ARTIFACTS_DIR / \"cross_corr_scan_pp_crude.csv\", index=False)\n",
    "else:\n",
    "    display(Markdown(\"**Add crude data to unlock headline visuals.**\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bee224d",
   "metadata": {},
   "source": [
    "_Figures recap:_ Rolling β tracks relationship strength, the beta-scaled spread highlights sustained divergence, the lead/lag heatmap surfaces timing asymmetry, and the scatter pinpoints outlier months that may warrant narrative follow-up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a87efb",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "Auto-generated bullets summarizing overlap and correlation insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not monthly_inner.empty and not log_returns.empty:\n",
    "    overlap = (\n",
    "        monthly_inner.index.min().date(),\n",
    "        monthly_inner.index.max().date(),\n",
    "        len(monthly_inner),\n",
    "    )\n",
    "    corr_pp_crude = None\n",
    "    if {\"PP\", \"CRUDE\"} <= set(log_returns.columns):\n",
    "        corr_pp_crude = log_returns[[\"PP\", \"CRUDE\"]].corr().iloc[0, 1]\n",
    "    bullets = [\n",
    "        f\"- Overlap: {overlap[0]} to {overlap[1]} ({overlap[2]} months).\",\n",
    "        f\"- PP vs Crude return correlation: {corr_pp_crude:.2f}.\" if corr_pp_crude is not None else \"- Crude returns unavailable.\",\n",
    "    ]\n",
    "    if Path(ARTIFACTS_DIR / \"cross_corr_scan_pp_crude.csv\").exists():\n",
    "        scan = pd.read_csv(ARTIFACTS_DIR / \"cross_corr_scan_pp_crude.csv\")\n",
    "        best = scan.iloc[scan[\"corr\"].abs().idxmax()]\n",
    "        bullets.append(\n",
    "            f\"- Best lead/lag (PP vs Crude): lag {int(best['lag'])} with corr {best['corr']:.2f}.\"\n",
    "        )\n",
    "    else:\n",
    "        bullets.append(\"- Add drivers (PGP/crude) to compute lead/lag diagnostics.\")\n",
    "    display(Markdown(\"\\n\".join(bullets)))\n",
    "else:\n",
    "    display(Markdown(\"**Not enough data for findings yet.**\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99348d11",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Pre/post regime comparisons (pandemic, trade policy).\n",
    "- Overlay supply shocks or tariff events on level charts.\n",
    "- Prototype ARDL/VAR models plus Granger causality.\n",
    "- Incorporate news or macro indicators as additional drivers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
